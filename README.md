# Machine Learning From Scratch

---

## ✅ Learning Plan & Progress

### **Part 1 – Fundamentals (Supervised Learning & Foundations)**
- [X] Linear Regression (closed-form + gradient descent)
- [X] Logistic Regression (binary)
- [X] Multinomial (Softmax) Logistic Regression
- [X] k-Nearest Neighbors
- [X] Naive Bayes (text classification)
- [X] Decision Trees
- [X] Random Forests
- [X] Support Vector Machines
- [X] Gradient Boosted Trees
- [X] Perceptron
- [X] Multilayer Perceptron (backprop in NumPy)
- [X] L1 and L2 Regularization (Ridge, Lasso)

---

### **Part 2 – Deep Learning**
- [ ] RNN (char-level)
- [ ] LSTM / GRU
- [ ] Transformer Encoder (classification)
- [ ] Tiny GPT (char-level LM)
- [ ] Batch Normalization
- [ ] Dropout
- [X] Weight Initialization (Xavier, He)

---

### **Part 3 – Unsupervised & Representation Learning**
- [X] k-Means
- [X] PCA
- [ ] Gaussian Mixture Models (EM)
- [X] Autoencoder
- [ ] t-SNE visualization

---

### **Part 4 – Reinforcement Learning**
- [ ] Multi-Armed Bandits (ε-greedy, UCB, Thompson)
- [ ] DQN (CartPole)
- [ ] Markov Decision Processes (MDPs) - State, action, transition, reward

---

## ✍️ Author
**Joseph Taewoo Kim**  
- B.S. Mathematics, Minor in Physics  
- SWE @ Meta (ML Infrastructure)  
- Aiming to bridge **mathematics, ML, and research**
