# Machine Learning From Scratch

---

## ‚úÖ Learning Plan & Progress

### **Part 1 ‚Äì Fundamentals (Supervised Learning & Foundations)**
- [X] Linear Regression (closed-form + gradient descent)
- [X] Logistic Regression (binary)
- [X] Multinomial (Softmax) Logistic Regression
- [X] k-Nearest Neighbors
- [X] Naive Bayes (text classification)
- [X] Decision Trees
- [X] Random Forests
- [ ] Support Vector Machines
- [ ] Gradient Boosted Trees
- [ ] Perceptron
- [ ] Multilayer Perceptron (backprop in NumPy)
- [ ] L1 and L2 Regularization (Ridge, Lasso)
- [ ] Bias-Variance Tradeoffs

---

### **Part 2 ‚Äì Deep Learning**
- [ ] CNN (LeNet-style)
- [ ] Activation function experiments
- [ ] RNN (char-level)
- [ ] LSTM / GRU
- [ ] Transformer Encoder (classification)
- [ ] Tiny GPT (char-level LM)
- [ ] Loss Functions (e.g., MSE, Cross-Entropy, etc.)
- [ ] Batch Normalization
- [ ] Dropout
- [ ] Weight Initialization (Xavier, He)

---

### **Part 3 ‚Äì Unsupervised & Representation Learning**
- [ ] k-Means
- [ ] PCA
- [ ] Gaussian Mixture Models (EM)
- [ ] Autoencoder
- [ ] Variational Autoencoder
- [ ] GAN (MNIST)
- [ ] DCGAN
- [ ] t-SNE visualization
- [ ] DBSCAN (density-based clustering)
- [ ] Agglomerative Clustering (hierarchical clustering)

---

### **Part 4 ‚Äì Reinforcement Learning**
- [ ] Multi-Armed Bandits (Œµ-greedy, UCB, Thompson)
- [ ] Value Iteration & Policy Iteration
- [ ] Q-Learning
- [ ] SARSA
- [ ] DQN (CartPole)
- [ ] Policy Gradient (REINFORCE)
- [ ] Actor-Critic (lite A2C)
- [ ] Markov Decision Processes (MDPs) - State, action, transition, reward
- [ ] Exploration vs. Exploitation Tradeoff
- [ ] Reward Shaping

---

### üöÄ Stretch Goals
- [ ] Graph Neural Networks (GCN)
- [ ] Normalizing Flows
- [ ] Diffusion Models (toy denoising model)
- [ ] Meta-Learning (MAML)

---

## ‚úçÔ∏è Author
**Joseph Taewoo Kim**  
- B.S. Mathematics, Minor in Physics  
- SWE @ Meta (ML Infrastructure)  
- Aiming to bridge **mathematics, ML, and research**